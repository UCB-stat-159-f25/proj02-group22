<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Project 2: Reproducibility in Natural Language Processing - proj02</title><meta property="og:title" content="Project 2: Reproducibility in Natural Language Processing - proj02"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/user/yau_christy/myst-build/proj02-group22/build/4ca599c12ad03712a9fa6f4c109e48cc.svg"/><meta property="og:image" content="/user/yau_christy/myst-build/proj02-group22/build/4ca599c12ad03712a9fa6f4c109e48cc.svg"/><link rel="stylesheet" href="/user/yau_christy/myst-build/proj02-group22/build/_assets/app-IZWEOBHI.css"/><link rel="stylesheet" href="/user/yau_christy/myst-build/proj02-group22/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/user/yau_christy/myst-build/proj02-group22/favicon.ico"/><link rel="stylesheet" href="/user/yau_christy/myst-build/proj02-group22/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/user/yau_christy/myst-build/proj02-group22/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="proj02" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/user/yau_christy/myst-build/proj02-group22/">proj02</a><a title="Contribution statement" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/yau_christy/myst-build/proj02-group22/contribution-statement">Contribution statement</a><a title="Project 2: Reproducibility in Natural Language Processing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/yau_christy/myst-build/proj02-group22/nlp-p01">Project 2: Reproducibility in Natural Language Processing</a><a title="Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/yau_christy/myst-build/proj02-group22/nlp-p02">Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization</a><a title="Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/yau_christy/myst-build/proj02-group22/nlp-p03">Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)</a><a title="Project 2: Reproducibility in Natural Language Processing" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/user/yau_christy/myst-build/proj02-group22/nlp-p04">Project 2: Reproducibility in Natural Language Processing</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/UCB-stat-159-f25/proj02-group22" title="GitHub Repository: UCB-stat-159-f25/proj02-group22" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><a href="https://github.com/UCB-stat-159-f25/proj02-group22/edit/main/nlp-P04.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Project 2: Reproducibility in Natural Language Processing</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><div id="ll5MHHCRYd" class="relative group/block"><h3 id="read-data" class="relative group"><span class="heading-text">Read Data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#read-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="mzPVY5vKee" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># imports
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use(&#x27;seaborn-v0_8-dark&#x27;) </code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="jWrpJ6vEvJVhq-fEesEDF" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left"></div></div><div id="s89iAWNwNa" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># read in SOTU.csv 
sou = pd.read_csv(&#x27;data/SOTU.csv&#x27;)
sou.head()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="1yLkkUjzCXg5QCUwPW_T2" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="Zm3ldmTmtF" class="relative group/block"></div><div id="EZW1DfUxXC" class="relative group/block"><h2 id="part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit" class="relative group"><span class="heading-text">Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):</p><ul><li><p>Topic evolution over time - see <a target="_blank" rel="noreferrer" href="https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization" class="">https://<wbr/>maartengr<wbr/>.github<wbr/>.io<wbr/>/BERTopic<wbr/>/getting<wbr/>_started<wbr/>/topicsovertime<wbr/>/topicsovertime<wbr/>.html<wbr/>#visualization</a></p></li><li><p>Word frequency over time - does the frequency of certain words change over time</p></li><li><p>Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden’s speeches similar to each other? How similar are they to Trump’s speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See <a target="_blank" rel="noreferrer" href="https://spacy.io/usage/linguistic-features#vectors-similarity" class="">https://<wbr/>spacy<wbr/>.io<wbr/>/usage<wbr/>/linguistic<wbr/>-features<wbr/>#vectors<wbr/>-similarity</a></p></li><li><p>Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see <a target="_blank" rel="noreferrer" href="https://spacy.io/usage/linguistic-features#named-entities" class="">https://<wbr/>spacy<wbr/>.io<wbr/>/usage<wbr/>/linguistic<wbr/>-features<wbr/>#named<wbr/>-entities</a></p></li><li><p>Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see <a target="_blank" rel="noreferrer" href="https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py" class="">https://<wbr/>scikit<wbr/>-learn<wbr/>.org<wbr/>/stable<wbr/>/auto<wbr/>_examples<wbr/>/text<wbr/>/plot<wbr/>_document<wbr/>_classification<wbr/>_20newsgroups<wbr/>.html<wbr/>#sphx<wbr/>-glr<wbr/>-auto<wbr/>-examples<wbr/>-text<wbr/>-plot<wbr/>-document<wbr/>-classification<wbr/>-20newsgroups<wbr/>-py</a></p></li></ul></div><div id="K7DbYtMFSe" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import matplotlib.pyplot as plt
import seaborn as sns
import re
import pandas as pd


def plot_word_frequency_over_time(df, target_words):
    data_rows = []
    for index, row in df.iterrows():
        year = row[&#x27;Year&#x27;]
        text = row[&#x27;Text&#x27;].lower() 
        
        
        total_words = len(text.split())
        
        if total_words == 0: continue
            
        for word in target_words:
           
            count = text.count(word)
            
            freq_per_1k = (count / total_words) * 1000
            
            data_rows.append({
                &#x27;Year&#x27;: year,
                &#x27;Word&#x27;: word,
                &#x27;Frequency&#x27;: freq_per_1k
            })
            
    freq_df = pd.DataFrame(data_rows)
    
    plt.figure(figsize=(14, 7))
    sns.lineplot(data=freq_df, x=&#x27;Year&#x27;, y=&#x27;Frequency&#x27;, hue=&#x27;Word&#x27;, linewidth=2)
    
    plt.title(&#x27;Word Frequency Over Time (per 1,000 words)&#x27;, fontsize=14)
    plt.ylabel(&#x27;Frequency per 1,000 words&#x27;, fontsize=12)
    plt.xlabel(&#x27;Year&#x27;, fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.legend(title=&#x27;Target Word&#x27;)  
    plt.subplots_adjust(hspace=0.5)
    plt.tight_layout()
    save_path = &quot;outputs/Part_4_plot_word_frequency_over_time.png&quot;
    plt.savefig(save_path, dpi=300, bbox_inches=&quot;tight&quot;)
    print(save_path)
    plt.show()



interesting_words = [&#x27;immigrant&#x27;, &#x27;economy&#x27;, &#x27;climate&#x27;, &#x27;china&#x27;, &#x27;japan&#x27;]

plot_word_frequency_over_time(sou, interesting_words)
plt.savefig(&quot;save_filename&quot;, dpi=300, bbox_inches=&quot;tight&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="U_5FUDt6Ho_c4hn-P6OdS" class="max-w-full overflow-x-auto m-0 group not-prose relative overflow-y-visible text-left mb-5"><div><pre class="text-sm font-thin font-system"><code><span>outputs/Part_4_plot_word_frequency_over_time.png
</span></code></pre></div><img src="/user/yau_christy/myst-build/proj02-group22/build/8f0110d7fc8147132571ea4476a60695.png" alt="&lt;Figure size 1400x700 with 1 Axes&gt;"/><div class="font-mono text-sm whitespace-pre-wrap"><code><span>&lt;Figure size 640x480 with 0 Axes&gt;</span></code></div></div></div><div id="SAddxGFiDA" class="relative group/block"><p>This section details the “Word Frequency Over Time” analysis, which tracks the normalized usage of five key terms: “immigrant,” “economy,” “climate,” “china,” and “japan”, across addresses to ensure fair comparison despite varying speech lengths. The resulting timeseries plot reveals distinct historical patterns: “Japan” exhibits a massive spike in the early 1940s corresponding to World War II, while “China” shows a steady rise beginning in the late 20th century, reflecting its growing geopolitical significance. “Economy” displays a cyclical pattern with peaks aligning with recessions, suggesting it is a reactive topic emphasized during downturns. Modern issues like “climate” appear only in recent decades, marking a shift in political priorities, while “immigrant” usage spikes in the modern era, likely tracking legislative debates. The sharp,  for foreign policy terms contrast with the recurrent, moderate peaks for domestic economic concerns, demonstrating the State of the Union’s role as a historical of shifting national priorities. The generated visualization is saved as <code>outputs/4_1_Word_Frequency_Over_Time.png</code>, with the underlying code documented in the <code>nlp-P04.ipynb</code> notebook.</p></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/user/yau_christy/myst-build/proj02-group22/nlp-p03"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">proj02</div>Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)</div></div></a></div></article></main><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-F7G67JTZ.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/root-7TUVC4ZT.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/_shared/chunk-INOWNUZ6.js"/><link rel="modulepreload" href="/user/yau_christy/myst-build/proj02-group22/build/routes/$-P6PGXPYX.js"/><script>window.__remixContext = {"url":"/nlp-p04","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.3","options":{},"nav":[],"actions":[],"projects":[{"github":"https://github.com/UCB-stat-159-f25/proj02-group22","id":"61e83804-e4e7-40aa-abb2-8a3c789a3fe1","toc":[{"file":"README.md"},{"file":"contribution_statement.md"},{"file":"nlp-P01.ipynb"},{"file":"nlp-P02.ipynb"},{"file":"nlp-P03.ipynb"},{"file":"nlp-P04.ipynb"}],"thumbnail":"/user/yau_christy/myst-build/proj02-group22/build/4ca599c12ad03712a9fa6f4c109e48cc.svg","exports":[],"bibliography":[],"title":"proj02","index":"index","pages":[{"slug":"contribution-statement","title":"Contribution statement","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p01","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p02","title":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p03","title":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p04","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/user/yau_christy/myst-build/proj02-group22"},"routes/$":{"config":{"version":2,"myst":"1.6.3","options":{},"nav":[],"actions":[],"projects":[{"github":"https://github.com/UCB-stat-159-f25/proj02-group22","id":"61e83804-e4e7-40aa-abb2-8a3c789a3fe1","toc":[{"file":"README.md"},{"file":"contribution_statement.md"},{"file":"nlp-P01.ipynb"},{"file":"nlp-P02.ipynb"},{"file":"nlp-P03.ipynb"},{"file":"nlp-P04.ipynb"}],"thumbnail":"/user/yau_christy/myst-build/proj02-group22/build/4ca599c12ad03712a9fa6f4c109e48cc.svg","exports":[],"bibliography":[],"title":"proj02","index":"index","pages":[{"slug":"contribution-statement","title":"Contribution statement","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p01","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p02","title":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p03","title":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p04","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":2,"kind":"Notebook","sha256":"d4213c80ca8c09e1b8af278a75f05677592548c74d45d951f5799c3a44cf87e2","slug":"nlp-p04","location":"/nlp-P04.ipynb","dependencies":[],"frontmatter":{"title":"Project 2: Reproducibility in Natural Language Processing","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"github":"https://github.com/UCB-stat-159-f25/proj02-group22","source_url":"https://github.com/UCB-stat-159-f25/proj02-group22/blob/main/nlp-P04.ipynb","edit_url":"https://github.com/UCB-stat-159-f25/proj02-group22/edit/main/nlp-P04.ipynb","exports":[{"format":"ipynb","filename":"nlp-P04.ipynb","url":"/user/yau_christy/myst-build/proj02-group22/build/nlp-P04-fc5bdf1a47d642f709358d60c859c9dd.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Read Data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KMFjDRmHUY"}],"identifier":"read-data","label":"Read Data","html_id":"read-data","implicit":true,"key":"OmPxJq318r"}],"key":"ll5MHHCRYd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn-v0_8-dark') ","key":"fkDWbnJ019"},{"type":"output","id":"jWrpJ6vEvJVhq-fEesEDF","data":[],"key":"xgagedOfbT"}],"key":"mzPVY5vKee"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# read in SOTU.csv \nsou = pd.read_csv('data/SOTU.csv')\nsou.head()","key":"LyJDUifBUP"},{"type":"output","id":"1yLkkUjzCXg5QCUwPW_T2","data":[{"output_type":"execute_result","execution_count":17,"metadata":{},"data":{"text/html":{"content":"\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003ePresident\u003c/th\u003e\n      \u003cth\u003eYear\u003c/th\u003e\n      \u003cth\u003eText\u003c/th\u003e\n      \u003cth\u003eWord Count\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003eJoseph R. Biden\u003c/td\u003e\n      \u003ctd\u003e2024.0\u003c/td\u003e\n      \u003ctd\u003e\\n[Before speaking, the President presented hi...\u003c/td\u003e\n      \u003ctd\u003e8003\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003eJoseph R. Biden\u003c/td\u003e\n      \u003ctd\u003e2023.0\u003c/td\u003e\n      \u003ctd\u003e\\nThe President. Mr. Speaker——\\n[At this point...\u003c/td\u003e\n      \u003ctd\u003e8978\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003eJoseph R. Biden\u003c/td\u003e\n      \u003ctd\u003e2022.0\u003c/td\u003e\n      \u003ctd\u003e\\nThe President. Thank you all very, very much...\u003c/td\u003e\n      \u003ctd\u003e7539\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003eJoseph R. Biden\u003c/td\u003e\n      \u003ctd\u003e2021.0\u003c/td\u003e\n      \u003ctd\u003e\\nThe President. Thank you. Thank you. Thank y...\u003c/td\u003e\n      \u003ctd\u003e7734\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003eDonald J. Trump\u003c/td\u003e\n      \u003ctd\u003e2020.0\u003c/td\u003e\n      \u003ctd\u003e\\nThe President. Thank you very much. Thank yo...\u003c/td\u003e\n      \u003ctd\u003e6169\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e","content_type":"text/html"},"text/plain":{"content":"         President    Year                                               Text  \\\n0  Joseph R. Biden  2024.0  \\n[Before speaking, the President presented hi...   \n1  Joseph R. Biden  2023.0  \\nThe President. Mr. Speaker——\\n[At this point...   \n2  Joseph R. Biden  2022.0  \\nThe President. Thank you all very, very much...   \n3  Joseph R. Biden  2021.0  \\nThe President. Thank you. Thank you. Thank y...   \n4  Donald J. Trump  2020.0  \\nThe President. Thank you very much. Thank yo...   \n\n   Word Count  \n0        8003  \n1        8978  \n2        7539  \n3        7734  \n4        6169  ","content_type":"text/plain"}}}],"key":"D5Pv3gVzMq"}],"key":"s89iAWNwNa"},{"type":"block","kind":"notebook-content","children":[],"key":"Zm3ldmTmtF"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vajIhgxd5l"}],"identifier":"part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit","label":"Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)","html_id":"part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit","implicit":true,"key":"YAUP3FqXtw"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FbIDPPr5z5"}],"key":"glocIaC6G7"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Topic evolution over time - see ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"rqykuyF4ah"},{"type":"link","url":"https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"https://​maartengr​.github​.io​/BERTopic​/getting​_started​/topicsovertime​/topicsovertime​.html​#visualization","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"poDYi92Ypw"}],"urlSource":"https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization","key":"cETX1IRPv1"}],"key":"pu6DsXoRb8"}],"key":"wz8MrsdPOn"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Word frequency over time - does the frequency of certain words change over time","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"eMdOOdcWiv"}],"key":"f2zTo0Eh7t"}],"key":"qXWTraTtL3"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden’s speeches similar to each other? How similar are they to Trump’s speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"RvavgKetH8"},{"type":"link","url":"https://spacy.io/usage/linguistic-features#vectors-similarity","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"https://​spacy​.io​/usage​/linguistic​-features​#vectors​-similarity","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"jSk1fWGiRa"}],"urlSource":"https://spacy.io/usage/linguistic-features#vectors-similarity","key":"bTT0f9YPjR"}],"key":"fKfNv9GWlu"}],"key":"o5KGYOm28d"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"sUxZx13Viw"},{"type":"link","url":"https://spacy.io/usage/linguistic-features#named-entities","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"https://​spacy​.io​/usage​/linguistic​-features​#named​-entities","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"xeoVCyF8yK"}],"urlSource":"https://spacy.io/usage/linguistic-features#named-entities","key":"bLUyxU7Jbl"}],"key":"rr6EgSSCUy"}],"key":"MqoXTLwE06"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"VrUOwyAkxy"},{"type":"link","url":"https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"https://​scikit​-learn​.org​/stable​/auto​_examples​/text​/plot​_document​_classification​_20newsgroups​.html​#sphx​-glr​-auto​-examples​-text​-plot​-document​-classification​-20newsgroups​-py","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"dAJudJQ9ic"}],"urlSource":"https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py","key":"ippBRUurYz"}],"key":"kOMx8lHkb8"}],"key":"CnWcVwlChF"}],"key":"vG8i0Zkq9X"}],"key":"EZW1DfUxXC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport pandas as pd\n\n\ndef plot_word_frequency_over_time(df, target_words):\n    data_rows = []\n    for index, row in df.iterrows():\n        year = row['Year']\n        text = row['Text'].lower() \n        \n        \n        total_words = len(text.split())\n        \n        if total_words == 0: continue\n            \n        for word in target_words:\n           \n            count = text.count(word)\n            \n            freq_per_1k = (count / total_words) * 1000\n            \n            data_rows.append({\n                'Year': year,\n                'Word': word,\n                'Frequency': freq_per_1k\n            })\n            \n    freq_df = pd.DataFrame(data_rows)\n    \n    plt.figure(figsize=(14, 7))\n    sns.lineplot(data=freq_df, x='Year', y='Frequency', hue='Word', linewidth=2)\n    \n    plt.title('Word Frequency Over Time (per 1,000 words)', fontsize=14)\n    plt.ylabel('Frequency per 1,000 words', fontsize=12)\n    plt.xlabel('Year', fontsize=12)\n    plt.grid(True, alpha=0.3)\n    plt.legend(title='Target Word')  \n    plt.subplots_adjust(hspace=0.5)\n    plt.tight_layout()\n    save_path = \"outputs/Part_4_plot_word_frequency_over_time.png\"\n    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n    print(save_path)\n    plt.show()\n\n\n\ninteresting_words = ['immigrant', 'economy', 'climate', 'china', 'japan']\n\nplot_word_frequency_over_time(sou, interesting_words)\nplt.savefig(\"save_filename\", dpi=300, bbox_inches=\"tight\")","key":"SW3qe0D40z"},{"type":"output","id":"U_5FUDt6Ho_c4hn-P6OdS","data":[{"name":"stdout","output_type":"stream","text":"outputs/Part_4_plot_word_frequency_over_time.png\n"},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"8f0110d7fc8147132571ea4476a60695","path":"/user/yau_christy/myst-build/proj02-group22/build/8f0110d7fc8147132571ea4476a60695.png"},"text/plain":{"content":"\u003cFigure size 1400x700 with 1 Axes\u003e","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 0 Axes\u003e","content_type":"text/plain"}}}],"key":"uIoX0VR1Y4"}],"key":"K7DbYtMFSe"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This section details the “Word Frequency Over Time” analysis, which tracks the normalized usage of five key terms: “immigrant,” “economy,” “climate,” “china,” and “japan”, across addresses to ensure fair comparison despite varying speech lengths. The resulting timeseries plot reveals distinct historical patterns: “Japan” exhibits a massive spike in the early 1940s corresponding to World War II, while “China” shows a steady rise beginning in the late 20th century, reflecting its growing geopolitical significance. “Economy” displays a cyclical pattern with peaks aligning with recessions, suggesting it is a reactive topic emphasized during downturns. Modern issues like “climate” appear only in recent decades, marking a shift in political priorities, while “immigrant” usage spikes in the modern era, likely tracking legislative debates. The sharp,  for foreign policy terms contrast with the recurrent, moderate peaks for domestic economic concerns, demonstrating the State of the Union’s role as a historical of shifting national priorities. The generated visualization is saved as ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tko2X82Xoj"},{"type":"inlineCode","value":"outputs/4_1_Word_Frequency_Over_Time.png","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rRIPaWvyeS"},{"type":"text","value":", with the underlying code documented in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tqmJVLElPZ"},{"type":"inlineCode","value":"nlp-P04.ipynb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IBQHUKG4he"},{"type":"text","value":" notebook.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"boN9Nm6VTy"}],"key":"zbxTT0VJes"}],"key":"SAddxGFiDA"}],"key":"NuXYrDHBzv"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","url":"/nlp-p03","group":"proj02"}}},"domain":"http://localhost:3000"},"project":{"github":"https://github.com/UCB-stat-159-f25/proj02-group22","id":"61e83804-e4e7-40aa-abb2-8a3c789a3fe1","toc":[{"file":"README.md"},{"file":"contribution_statement.md"},{"file":"nlp-P01.ipynb"},{"file":"nlp-P02.ipynb"},{"file":"nlp-P03.ipynb"},{"file":"nlp-P04.ipynb"}],"thumbnail":"/user/yau_christy/myst-build/proj02-group22/build/4ca599c12ad03712a9fa6f4c109e48cc.svg","exports":[],"bibliography":[],"title":"proj02","index":"index","pages":[{"slug":"contribution-statement","title":"Contribution statement","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p01","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p02","title":"Part 2: Simple Text Processing - Tokenization, Lemmatization, Word Frequency, Vectorization","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p03","title":"Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"nlp-p04","title":"Project 2: Reproducibility in Natural Language Processing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/user/yau_christy/myst-build/proj02-group22/build/manifest-3481E987.js";
import * as route0 from "/user/yau_christy/myst-build/proj02-group22/build/root-7TUVC4ZT.js";
import * as route1 from "/user/yau_christy/myst-build/proj02-group22/build/routes/$-P6PGXPYX.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/user/yau_christy/myst-build/proj02-group22/build/entry.client-UNPC4GT3.js");</script></body></html>