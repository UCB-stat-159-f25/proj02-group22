{"version":2,"kind":"Notebook","sha256":"d4213c80ca8c09e1b8af278a75f05677592548c74d45d951f5799c3a44cf87e2","slug":"nlp-p04","location":"/nlp-P04.ipynb","dependencies":[],"frontmatter":{"title":"Project 2: Reproducibility in Natural Language Processing","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"github":"https://github.com/UCB-stat-159-f25/proj02-group22","source_url":"https://github.com/UCB-stat-159-f25/proj02-group22/blob/main/nlp-P04.ipynb","edit_url":"https://github.com/UCB-stat-159-f25/proj02-group22/edit/main/nlp-P04.ipynb","exports":[{"format":"ipynb","filename":"nlp-P04.ipynb","url":"/nlp-P04-fc5bdf1a47d642f709358d60c859c9dd.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Read Data","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KMFjDRmHUY"}],"identifier":"read-data","label":"Read Data","html_id":"read-data","implicit":true,"key":"OmPxJq318r"}],"key":"ll5MHHCRYd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('seaborn-v0_8-dark') ","key":"fkDWbnJ019"},{"type":"output","id":"jWrpJ6vEvJVhq-fEesEDF","data":[],"key":"xgagedOfbT"}],"key":"mzPVY5vKee"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# read in SOTU.csv \nsou = pd.read_csv('data/SOTU.csv')\nsou.head()","key":"LyJDUifBUP"},{"type":"output","id":"1yLkkUjzCXg5QCUwPW_T2","data":[{"output_type":"execute_result","execution_count":17,"metadata":{},"data":{"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>President</th>\n      <th>Year</th>\n      <th>Text</th>\n      <th>Word Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Joseph R. Biden</td>\n      <td>2024.0</td>\n      <td>\\n[Before speaking, the President presented hi...</td>\n      <td>8003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Joseph R. Biden</td>\n      <td>2023.0</td>\n      <td>\\nThe President. Mr. Speaker——\\n[At this point...</td>\n      <td>8978</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Joseph R. Biden</td>\n      <td>2022.0</td>\n      <td>\\nThe President. Thank you all very, very much...</td>\n      <td>7539</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Joseph R. Biden</td>\n      <td>2021.0</td>\n      <td>\\nThe President. Thank you. Thank you. Thank y...</td>\n      <td>7734</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Donald J. Trump</td>\n      <td>2020.0</td>\n      <td>\\nThe President. Thank you very much. Thank yo...</td>\n      <td>6169</td>\n    </tr>\n  </tbody>\n</table>\n</div>","content_type":"text/html"},"text/plain":{"content":"         President    Year                                               Text  \\\n0  Joseph R. Biden  2024.0  \\n[Before speaking, the President presented hi...   \n1  Joseph R. Biden  2023.0  \\nThe President. Mr. Speaker——\\n[At this point...   \n2  Joseph R. Biden  2022.0  \\nThe President. Thank you all very, very much...   \n3  Joseph R. Biden  2021.0  \\nThe President. Thank you. Thank you. Thank y...   \n4  Donald J. Trump  2020.0  \\nThe President. Thank you very much. Thank yo...   \n\n   Word Count  \n0        8003  \n1        8978  \n2        7539  \n3        7734  \n4        6169  ","content_type":"text/plain"}}}],"key":"D5Pv3gVzMq"}],"key":"s89iAWNwNa"},{"type":"block","kind":"notebook-content","children":[],"key":"Zm3ldmTmtF"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vajIhgxd5l"}],"identifier":"part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit","label":"Part 4: Choose your own advecnture! (7 Points; Optional for Extra Credit)","html_id":"part-4-choose-your-own-advecnture-7-points-optional-for-extra-credit","implicit":true,"key":"YAUP3FqXtw"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This section is open ended and your chance to explare any advanced analysis. Please perform any additional analysis you find interesting! Suggested analyses (only do one max):","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FbIDPPr5z5"}],"key":"glocIaC6G7"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Topic evolution over time - see ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"rqykuyF4ah"},{"type":"link","url":"https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"https://​maartengr​.github​.io​/BERTopic​/getting​_started​/topicsovertime​/topicsovertime​.html​#visualization","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"poDYi92Ypw"}],"urlSource":"https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html#visualization","key":"cETX1IRPv1"}],"key":"pu6DsXoRb8"}],"key":"wz8MrsdPOn"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Word frequency over time - does the frequency of certain words change over time","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"eMdOOdcWiv"}],"key":"f2zTo0Eh7t"}],"key":"qXWTraTtL3"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Semantic similarity - investigate similarity within and between presidents or time periods. For example, similarity between one presidents speeches, e.g. are all of Biden’s speeches similar to each other? How similar are they to Trump’s speeches? Are speeches from the 2000s more similar to each other than speeches in the 1800s? Which two presidents have the most similar speeches? See ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"RvavgKetH8"},{"type":"link","url":"https://spacy.io/usage/linguistic-features#vectors-similarity","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"https://​spacy​.io​/usage​/linguistic​-features​#vectors​-similarity","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"jSk1fWGiRa"}],"urlSource":"https://spacy.io/usage/linguistic-features#vectors-similarity","key":"bTT0f9YPjR"}],"key":"fKfNv9GWlu"}],"key":"o5KGYOm28d"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Named Entity Recognition - which entity types are most common in speeches? What are the most common words for each entity type - see ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"sUxZx13Viw"},{"type":"link","url":"https://spacy.io/usage/linguistic-features#named-entities","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"https://​spacy​.io​/usage​/linguistic​-features​#named​-entities","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"xeoVCyF8yK"}],"urlSource":"https://spacy.io/usage/linguistic-features#named-entities","key":"bLUyxU7Jbl"}],"key":"rr6EgSSCUy"}],"key":"MqoXTLwE06"},{"type":"listItem","spread":true,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Classification - can you build a classifier to detect democratic versus republican state of the union speeches from 1980-2024 - see ","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"VrUOwyAkxy"},{"type":"link","url":"https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"https://​scikit​-learn​.org​/stable​/auto​_examples​/text​/plot​_document​_classification​_20newsgroups​.html​#sphx​-glr​-auto​-examples​-text​-plot​-document​-classification​-20newsgroups​-py","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"dAJudJQ9ic"}],"urlSource":"https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py","key":"ippBRUurYz"}],"key":"kOMx8lHkb8"}],"key":"CnWcVwlChF"}],"key":"vG8i0Zkq9X"}],"key":"EZW1DfUxXC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport pandas as pd\n\n\ndef plot_word_frequency_over_time(df, target_words):\n    data_rows = []\n    for index, row in df.iterrows():\n        year = row['Year']\n        text = row['Text'].lower() \n        \n        \n        total_words = len(text.split())\n        \n        if total_words == 0: continue\n            \n        for word in target_words:\n           \n            count = text.count(word)\n            \n            freq_per_1k = (count / total_words) * 1000\n            \n            data_rows.append({\n                'Year': year,\n                'Word': word,\n                'Frequency': freq_per_1k\n            })\n            \n    freq_df = pd.DataFrame(data_rows)\n    \n    plt.figure(figsize=(14, 7))\n    sns.lineplot(data=freq_df, x='Year', y='Frequency', hue='Word', linewidth=2)\n    \n    plt.title('Word Frequency Over Time (per 1,000 words)', fontsize=14)\n    plt.ylabel('Frequency per 1,000 words', fontsize=12)\n    plt.xlabel('Year', fontsize=12)\n    plt.grid(True, alpha=0.3)\n    plt.legend(title='Target Word')  \n    plt.subplots_adjust(hspace=0.5)\n    plt.tight_layout()\n    save_path = \"outputs/Part_4_plot_word_frequency_over_time.png\"\n    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n    print(save_path)\n    plt.show()\n\n\n\ninteresting_words = ['immigrant', 'economy', 'climate', 'china', 'japan']\n\nplot_word_frequency_over_time(sou, interesting_words)\nplt.savefig(\"save_filename\", dpi=300, bbox_inches=\"tight\")","key":"SW3qe0D40z"},{"type":"output","id":"U_5FUDt6Ho_c4hn-P6OdS","data":[{"name":"stdout","output_type":"stream","text":"outputs/Part_4_plot_word_frequency_over_time.png\n"},{"output_type":"display_data","metadata":{},"data":{"image/png":{"content_type":"image/png","hash":"8f0110d7fc8147132571ea4476a60695","path":"/8f0110d7fc8147132571ea4476a60695.png"},"text/plain":{"content":"<Figure size 1400x700 with 1 Axes>","content_type":"text/plain"}}},{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 640x480 with 0 Axes>","content_type":"text/plain"}}}],"key":"uIoX0VR1Y4"}],"key":"K7DbYtMFSe"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"This section details the “Word Frequency Over Time” analysis, which tracks the normalized usage of five key terms: “immigrant,” “economy,” “climate,” “china,” and “japan”, across addresses to ensure fair comparison despite varying speech lengths. The resulting timeseries plot reveals distinct historical patterns: “Japan” exhibits a massive spike in the early 1940s corresponding to World War II, while “China” shows a steady rise beginning in the late 20th century, reflecting its growing geopolitical significance. “Economy” displays a cyclical pattern with peaks aligning with recessions, suggesting it is a reactive topic emphasized during downturns. Modern issues like “climate” appear only in recent decades, marking a shift in political priorities, while “immigrant” usage spikes in the modern era, likely tracking legislative debates. The sharp,  for foreign policy terms contrast with the recurrent, moderate peaks for domestic economic concerns, demonstrating the State of the Union’s role as a historical of shifting national priorities. The generated visualization is saved as ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tko2X82Xoj"},{"type":"inlineCode","value":"outputs/4_1_Word_Frequency_Over_Time.png","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rRIPaWvyeS"},{"type":"text","value":", with the underlying code documented in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tqmJVLElPZ"},{"type":"inlineCode","value":"nlp-P04.ipynb","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IBQHUKG4he"},{"type":"text","value":" notebook.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"boN9Nm6VTy"}],"key":"zbxTT0VJes"}],"key":"SAddxGFiDA"}],"key":"NuXYrDHBzv"},"references":{"cite":{"order":[],"data":{}}}}